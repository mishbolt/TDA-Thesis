{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gudhi as gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mat73\n",
    "def data():\n",
    "    Data=mat73.loadmat('/scratch/mb2864/Data/GE_Data_221013_normPH.mat', use_attrdict=True)\n",
    "    return Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Persistence Diagrams in a list\n",
    "ListOfPDs=[]\n",
    "for j in range(850):\n",
    "    pers_diag=Data.X.h0_t20_n_flip[j]\n",
    "    pers_diag=np.array(pers_diag)\n",
    "    ListOfPDs.append(pers_diag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from gudhi.representations import PersistenceImage\n",
    "\n",
    "#Persistence Images\n",
    "\n",
    "PI = PersistenceImage(bandwidth=0.5, weight=lambda x: 1/(1+np.exp(-x[1]+x[0])), \\\n",
    "                                       im_range=[-4,3,-3,3],   resolution=[50,50])\n",
    "pi=PI.fit_transform(ListOfPDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coord_matrix():\n",
    "    \n",
    "    #gudhi.plot_persistence_diagram(data.X.h0_t20[2])\n",
    "    \n",
    "    f1=np.zeros([850,1])\n",
    "    f2=np.zeros([850,1])\n",
    "    f3=np.zeros([850,1])\n",
    "    f4=np.zeros([850,1])\n",
    "    f5=np.zeros([850,1])\n",
    "    f6=np.zeros([850,1])\n",
    "    M= np.zeros([850,10])\n",
    "    \n",
    "    for k in range(2):\n",
    "        for j in range(850):\n",
    "            if k==0:\n",
    "                H0_pers=Data.X.h0_t20_n[j]\n",
    "            if k==1:\n",
    "                H0_pers=Data.X.h1_t20_n[j]\n",
    "            H0_pers=np.array(H0_pers)    \n",
    "            p=[H0_pers[i,1]-H0_pers[i,0] for i in range(len(H0_pers))]\n",
    "            \n",
    "            p=np.array(p)\n",
    "            \n",
    "            b=H0_pers[:,0]\n",
    "            d=H0_pers[:,1]\n",
    "            b=np.array(b)\n",
    "            d=np.array(d)\n",
    "            d_max=np.max(d)\n",
    "            #Carlson Coordinates\n",
    "            f1[j]=np.sum(d*p)/len(d) \n",
    "            f2[j]=(d_max*np.sum(p)-np.sum(d*p))/len(d)\n",
    "            f3[j]=np.sum(b**2*(p)**4)/len(d)\n",
    "            f4[j]=d_max**2*np.sum((1-d/d_max)**2*p**4)/len(d)\n",
    "            f5[j]=np.max(p)\n",
    "            #f6[j]=np.sum(1/p)\n",
    "        if k==0:\n",
    "            M[:,0:5]=np.concatenate((f1,f2,f3,f4,f5),axis=1)\n",
    "        else:\n",
    "            M[:,5:10]=np.concatenate((f1,f2,f3,f4,f5),axis=1)\n",
    "\n",
    "    return(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "SurfaceStacked=np.zeros([40000,850])\n",
    "for i in range(850):\n",
    "    Surface=np.array(Data.X.hknorm[i])\n",
    "    Surface=Surface[:,:,19]\n",
    "    SurfaceColumn=np.reshape(Surface.T,(40000,1))\n",
    "    SurfaceStacked[:,i] = SurfaceColumn.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__algorithm': 'auto', 'knn__n_neighbors': 11}\n",
      "KNN score: 0.711764705882353\n",
      "{'svm__C': 10, 'svm__gamma': 'scale', 'svm__kernel': 'rbf'}\n",
      "SVC score: 0.7235294117647059\n",
      "{'rfc__criterion': 'gini'}\n",
      "RandomForest score: 0.6882352941176471\n",
      "{'nnet__alpha': 0.0001, 'nnet__max_iter': 1000}\n",
      "Neural Net score: 0.38823529411764707\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing   import MinMaxScaler\n",
    "from sklearn.pipeline        import Pipeline\n",
    "from sklearn.svm             import SVC\n",
    "from sklearn.ensemble        import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, NeighborhoodComponentsAnalysis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from gudhi.representations import PersistenceImage\n",
    "\n",
    "\n",
    "#X=ListOfPDs\n",
    "X=pi\n",
    "#X=coord_matrix()\n",
    "#X=SurfaceStacked.T\n",
    "\n",
    "lbls=np.zeros([850,1])\n",
    "for j in range(17):\n",
    "    lbls[50*j:50*j+50]=j*np.ones([50,1])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, lbls, test_size=0.2, random_state=0)\n",
    "\n",
    "classifiers = [\n",
    "    Pipeline(\n",
    "        [\n",
    "            #(\"preprocess\", PersistenceImage()),\n",
    "            (\"knn\", KNeighborsClassifier())\n",
    "        ]\n",
    "    ),\n",
    "    Pipeline(\n",
    "        [   #(\"preprocess\", PersistenceImage()),\n",
    "            (\"svm\", SVC())\n",
    "        ]\n",
    "    ),\n",
    "    Pipeline(\n",
    "        [   #(\"preprocess\", PersistenceImage()),\n",
    "            (\"rfc\", RandomForestClassifier())\n",
    "        ]\n",
    "    ),\n",
    "    Pipeline(\n",
    "        [   #(\"preprocess\", PersistenceImage()),\n",
    "            (\"nnet\", MLPClassifier())\n",
    "        ]\n",
    "    ),\n",
    "]\n",
    "\n",
    "names=[\"KNN\",\"SVC\",\"RandomForest\",\"Neural Net\"]\n",
    "\n",
    "param_grid=[#{'preprocess__bandwidth':[1], 'preprocess__weight':[lambda x: np.tanh(x[1])],'preprocess__im_range':\\\n",
    "             #[[-4,3,-3,3]],   'preprocess__resolution':[[50,50]]},\n",
    "            {'knn__n_neighbors': [1, 3, 5, 7, 9, 11], 'knn__algorithm': ['auto']},\n",
    "            {'svm__C': [1, 10], 'svm__kernel': ['linear', 'rbf'],'svm__gamma':['auto','scale']},\n",
    "            {'rfc__criterion': ['gini','entropy']},\n",
    "            {'nnet__alpha': [0.0001],'nnet__max_iter':[1000,2000]}]\n",
    "\n",
    "\n",
    "for name,clf,params in zip(names,classifiers,param_grid):\n",
    "    model = GridSearchCV(clf, params, cv=5)\n",
    "    model_fit= model.fit(X_train,np.ravel(y_train))\n",
    "    print(model.best_params_)\n",
    "    score= model_fit.score(X_test, y_test)\n",
    "    print(\"{} score: {}\".format(name, score))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(850,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(ListOfPDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd.representations.preprocessing.ProminentPoints"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
